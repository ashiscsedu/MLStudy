\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Vector Space}{1}{section.1}}
\newlabel{term:vector_space}{{1}{1}{Vector Space}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Vector Subspace}{1}{section.2}}
\newlabel{term_vector_subspace}{{2}{1}{Vector Subspace}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Linear Span}{1}{section.3}}
\newlabel{term:linear_span}{{3}{1}{Linear Span}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Linearly Independent Vectors}{1}{section.4}}
\newlabel{term:linearly_independent_vectors}{{4}{1}{Linearly Independent Vectors}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Basis}{2}{section.5}}
\newlabel{term:basis}{{5}{2}{Basis}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Rank of a Matrix}{2}{section.6}}
\newlabel{term:rank_of_a_matrix}{{6}{2}{Rank of a Matrix}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Singular Matrix}{2}{section.7}}
\newlabel{term:singular_matrix}{{7}{2}{Singular Matrix}{section.7}{}}
\citation{chiang2005fundamental}
\citation{akivis2012introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces This picture illustrates the standard basis in $\mathbb  {R}^2$. The blue and orange vectors are the elements of the basis; the green vector can be given in terms of the basis vectors, and so is linearly dependent upon them. This picture illustrates how two vectors in $\mathbb  {R}^2$ (or $\mathbb  {R} \times \mathbb  {R}$) can be written in terms of the standard basis. $B = \{(1,0), (0,1)\}$. Notice how $\text  {span}(B) = \mathbb  {R}^2$, and how (-2, 1) = (-2)(1,0) + (1)(0,1). Reference \url  {https://en.wikipedia.org/wiki/Basis_(linear_algebra)} (Last accessed: 10/28/2014, 2:04AM)}}{3}{figure.1}}
\newlabel{fig:basis}{{1}{3}{This picture illustrates the standard basis in $\mathbb {R}^2$. The blue and orange vectors are the elements of the basis; the green vector can be given in terms of the basis vectors, and so is linearly dependent upon them. This picture illustrates how two vectors in $\mathbb {R}^2$ (or $\mathbb {R} \times \mathbb {R}$) can be written in terms of the standard basis. $B = \{(1,0), (0,1)\}$. Notice how $\text {span}(B) = \mathbb {R}^2$, and how (-2, 1) = (-2)(1,0) + (1)(0,1). Reference \url {https://en.wikipedia.org/wiki/Basis_(linear_algebra)} (Last accessed: 10/28/2014, 2:04AM)}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Idempotent Matrix}{3}{section.8}}
\newlabel{term:idempotent_matrix}{{8}{3}{Idempotent Matrix}{section.8}{}}
\@writefile{brf}{\backcite{chiang2005fundamental}{{3}{8}{section.8}}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Diagonal Matrix}{3}{section.9}}
\newlabel{term:diagonal_matrix}{{9}{3}{Diagonal Matrix}{section.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Identity Matrix}{3}{section.10}}
\newlabel{term:identity_matrix}{{10}{3}{Identity Matrix}{section.10}{}}
\@writefile{brf}{\backcite{akivis2012introduction}{{4}{10}{equation.10.1}}}
\citation{wiki:TriangularMatrix}
\@writefile{toc}{\contentsline {section}{\numberline {11}Triangular Matrix}{5}{section.11}}
\newlabel{term:triangular_matrix}{{11}{5}{Triangular Matrix}{section.11}{}}
\@writefile{brf}{\backcite{wiki:TriangularMatrix}{{5}{11}{section.11}}}
\citation{wiki:GaussianElimination}
\@writefile{toc}{\contentsline {section}{\numberline {12}Row Echelon Form}{6}{section.12}}
\newlabel{term:row_echelon_form}{{12}{6}{Row Echelon Form}{section.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Gauss-Jordan Elimination Algorithm}{6}{section.13}}
\newlabel{term:gauss_jordan_elimination_algorithm}{{13}{6}{Gauss-Jordan Elimination Algorithm}{section.13}{}}
\@writefile{brf}{\backcite{wiki:GaussianElimination}{{6}{13}{section.13}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Solving system of linear equations}{7}{subsection.13.1}}
\newlabel{term:gauss_jordan_elimination_algorithm_solve_systems}{{13.1}{7}{Solving system of linear equations}{subsection.13.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Computing Determinant of matrix}{7}{subsection.13.2}}
\newlabel{term:gauss_jordan_elimination_algorithm_compute_determinant}{{13.2}{7}{Computing Determinant of matrix}{subsection.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Computing rank of matrix}{8}{subsection.13.3}}
\newlabel{term:gauss_jordan_elimination_algorithm_compute_rank}{{13.3}{8}{Computing rank of matrix}{subsection.13.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4}Computing inverse of matrix}{9}{subsection.13.4}}
\newlabel{term:term:gauss_jordan_elimination_algorithm_compute_inverse}{{13.4}{9}{Computing inverse of matrix}{subsection.13.4}{}}
\citation{wiki:InvertibleMatrix}
\@writefile{toc}{\contentsline {section}{\numberline {14}Inverse of Matrix}{10}{section.14}}
\newlabel{term:inverse_matrix}{{14}{10}{Inverse of Matrix}{section.14}{}}
\@writefile{brf}{\backcite{wiki:InvertibleMatrix}{{10}{14}{section.14}}}
\@writefile{toc}{\contentsline {section}{\numberline {15}System of Linear Equations}{11}{section.15}}
\newlabel{term:linear_systems}{{15}{11}{System of Linear Equations}{section.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16}Dot Product of two vectors}{12}{section.16}}
\newlabel{term:dot_product}{{16}{12}{Dot Product of two vectors}{section.16}{}}
\citation{press1987numerical}
\@writefile{toc}{\contentsline {section}{\numberline {17}Unit vector}{13}{section.17}}
\newlabel{term:unit_vector}{{17}{13}{Unit vector}{section.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18}Matrix Product}{13}{section.18}}
\newlabel{term:matrix_product}{{18}{13}{Matrix Product}{section.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {19}Transpose of a Matrix}{13}{section.19}}
\newlabel{term:transpose_of_a_matrix}{{19}{13}{Transpose of a Matrix}{section.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {20}Eigenvalues and Eigenvectors}{13}{section.20}}
\newlabel{term:eigenvalues_and_eigenvectors}{{20}{13}{Eigenvalues and Eigenvectors}{section.20}{}}
\@writefile{brf}{\backcite{press1987numerical}{{13}{20}{section.20}}}
\newlabel{eqn:eigenvalue1}{{8}{14}{Eigenvalues and Eigenvectors}{equation.20.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21}Norm of vectors}{16}{section.21}}
\newlabel{term:norm_of_vectors}{{21}{16}{Norm of vectors}{section.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.1}Euclidean norm of a vector}{16}{subsection.21.1}}
\newlabel{term:euclidean_norm}{{21.1}{16}{Euclidean norm of a vector}{subsection.21.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.2}Manhattan norm of a vector}{16}{subsection.21.2}}
\newlabel{term:manhattan_norm}{{21.2}{16}{Manhattan norm of a vector}{subsection.21.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.3}$p$-Norm of a vector}{16}{subsection.21.3}}
\newlabel{term:p-norm}{{21.3}{16}{$p$-Norm of a vector}{subsection.21.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.4}Maximum Norm of a vector}{16}{subsection.21.4}}
\newlabel{term:maximum_norm}{{21.4}{16}{Maximum Norm of a vector}{subsection.21.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {22}Norm of Matrices}{16}{section.22}}
\newlabel{term:norm_of_matrices}{{22}{16}{Norm of Matrices}{section.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1}$L_1$-norm of a matrix}{16}{subsection.22.1}}
\newlabel{term:l1_norm_of_a_matrix}{{22.1}{16}{$L_1$-norm of a matrix}{subsection.22.1}{}}
\citation{ding2006r}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.2}Inifinity-norm of a matrix}{17}{subsection.22.2}}
\newlabel{term:infinity_norm_of_a_matrix}{{22.2}{17}{Inifinity-norm of a matrix}{subsection.22.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.3}Euclidean-norm of a matrix}{17}{subsection.22.3}}
\newlabel{term:euclidean_norm_of_a_matrix}{{22.3}{17}{Euclidean-norm of a matrix}{subsection.22.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.4}$L_{2,1}$-norm of a matrix}{17}{subsection.22.4}}
\newlabel{term:l_2,1_norm_of_a_matrix}{{22.4}{17}{$L_{2,1}$-norm of a matrix}{subsection.22.4}{}}
\@writefile{brf}{\backcite{ding2006r}{{17}{22.4}{subsection.22.4}}}
\citation{introduction_to_derivatives}
\citation{intuition_for_the_derivative}
\citation{opencalc2}
\@writefile{toc}{\contentsline {section}{\numberline {23}Derivative}{18}{section.23}}
\newlabel{term:derivative}{{23}{18}{Derivative}{section.23}{}}
\newlabel{eqn:derivative-1}{{10}{18}{Derivative}{equation.23.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Understanding the derivative of a function as the slope of the secant line going through the two points on the function $(x,f(x))$ and $((x+\Delta x),f(x+\Delta x))$.}}{18}{figure.2}}
\newlabel{fig:derivative-1}{{2}{18}{Understanding the derivative of a function as the slope of the secant line going through the two points on the function $(x,f(x))$ and $((x+\Delta x),f(x+\Delta x))$}{figure.2}{}}
\@writefile{brf}{\backcite{introduction_to_derivatives}{{18}{23}{figure.3}}}
\@writefile{brf}{\backcite{intuition_for_the_derivative}{{18}{23}{figure.3}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Deriviative is the slope of the function $f(x)$ at point $x$.}}{19}{figure.3}}
\newlabel{fig:derivative-2}{{3}{19}{Deriviative is the slope of the function $f(x)$ at point $x$}{figure.3}{}}
\@writefile{brf}{\backcite{opencalc2}{{19}{23}{equation.23.11}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The plot of a function $f(x)$. The first derivatives of the function at points $p_1, p_2, p_3, p_4, p_5, p_6, p_7$ are zero; we see that the tangent lines on these points have slope 0, i.e., are parallel to the $X$ axis, $\text  {tan}\theta = \left .\genfrac  {}{}{}0{df}{dx}\right |_{x=p_i} = 0$, for $i=1\cdots  7$. So, these 7 points are called the critical points of the function. We can't say anything further than this phenomenon whether the critical points are either local minimum, or local maximum by looking at the critical points alone. That's why we need the second derivative test.}}{20}{figure.4}}
\newlabel{fig:derivative-3}{{4}{20}{The plot of a function $f(x)$. The first derivatives of the function at points $p_1, p_2, p_3, p_4, p_5, p_6, p_7$ are zero; we see that the tangent lines on these points have slope 0, i.e., are parallel to the $X$ axis, $\text {tan}\theta = \left .\dfrac {df}{dx}\right |_{x=p_i} = 0$, for $i=1\cdots 7$. So, these 7 points are called the critical points of the function. We can't say anything further than this phenomenon whether the critical points are either local minimum, or local maximum by looking at the critical points alone. That's why we need the second derivative test}{figure.4}{}}
\citation{wiki:PartialDerivative}
\citation{khan:PartialDerivative}
\@writefile{toc}{\contentsline {section}{\numberline {24}Partial Derivative}{21}{section.24}}
\newlabel{term:partial_derivative}{{24}{21}{Partial Derivative}{section.24}{}}
\@writefile{brf}{\backcite{wiki:PartialDerivative}{{21}{24}{section.24}}}
\@writefile{brf}{\backcite{khan:PartialDerivative}{{21}{24}{section.24}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualizing the 3D Euclidean space using the right hand rule. The unit vector acros the $Z$ axis, $\mathaccentV {hat}05E{k}$ is equal to the cross product of the unit vectors across the $X$ and $Y$ axes, $\mathaccentV {hat}05E{i}$ and $\mathaccentV {hat}05E{j}$ respectively. That is, $\mathaccentV {hat}05E{k} = \mathaccentV {hat}05E{i}\times \mathaccentV {hat}05E{j}$}}{21}{figure.5}}
\newlabel{fig:partial-derivative-1}{{5}{21}{Visualizing the 3D Euclidean space using the right hand rule. The unit vector acros the $Z$ axis, $\hat {k}$ is equal to the cross product of the unit vectors across the $X$ and $Y$ axes, $\hat {i}$ and $\hat {j}$ respectively. That is, $\hat {k} = \hat {i}\times \hat {j}$}{figure.5}{}}
\citation{mathInsight:DirectionalDerivative}
\citation{mathInsight:DirectionalDerivative}
\citation{mathInsight:DirectionalDerivative}
\@writefile{toc}{\contentsline {section}{\numberline {25}Directional Derivative}{24}{section.25}}
\newlabel{term:directional_derivative}{{25}{24}{Directional Derivative}{section.25}{}}
\@writefile{brf}{\backcite{mathInsight:DirectionalDerivative}{{24}{25}{section.25}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Directional derivative on a mountain\cite  {mathInsight:DirectionalDerivative}. The height of a mountain range described by a function $f(x,y)$ is shown as surface plot in 3D (left), and a 2-D level curve plot (contour) (right). In each panel, a red point is the viewer, or the point where the directional derivative is to be evaluated. The directional derivative is computed in the direction of the 2D vector $\mathaccentV {vec}17Eu$. The direction is illustrated by the light green vectors as well shown in the lower left. The direction of $\mathaccentV {vec}17Eu$ is determined by the angle $\theta $ it makes with straight east (positive $x$ direction). The 2D point $\mathaccentV {vec}17Ea$ where the directional derivative is computed is illustrated by the shadow of the red point on the $xy$-plane below the surface plot and by the red point itself on the level curve plot. The value of the directional derivative $D_{\mathaccentV {vec}17Eu}f(\mathaccentV {vec}17Ea)$ is shown at the bottom of the panel, along with the value of $\mathaccentV {vec}17Ea$ itself. The value of $D_{\mathaccentV {vec}17Eu}f(\mathaccentV {vec}17Ea)$ is thes lope of the dark green vector to its right. This dark green vector is also shown emanating from the red point on the surface plot, where it is tangent to the surface, indicating that this slope is indeed the slope of the surface in the direction given by $\mathaccentV {vec}17Eu$. The height of the surface $f(\mathaccentV {vec}17Ea)$ is illustrated by the blue bar in the lower right.}}{25}{figure.6}}
\newlabel{fig:directional_derivative_1}{{6}{25}{Directional derivative on a mountain\cite {mathInsight:DirectionalDerivative}. The height of a mountain range described by a function $f(x,y)$ is shown as surface plot in 3D (left), and a 2-D level curve plot (contour) (right). In each panel, a red point is the viewer, or the point where the directional derivative is to be evaluated. The directional derivative is computed in the direction of the 2D vector $\vec u$. The direction is illustrated by the light green vectors as well shown in the lower left. The direction of $\vec u$ is determined by the angle $\theta $ it makes with straight east (positive $x$ direction). The 2D point $\vec a$ where the directional derivative is computed is illustrated by the shadow of the red point on the $xy$-plane below the surface plot and by the red point itself on the level curve plot. The value of the directional derivative $D_{\vec u}f(\vec a)$ is shown at the bottom of the panel, along with the value of $\vec a$ itself. The value of $D_{\vec u}f(\vec a)$ is thes lope of the dark green vector to its right. This dark green vector is also shown emanating from the red point on the surface plot, where it is tangent to the surface, indicating that this slope is indeed the slope of the surface in the direction given by $\vec u$. The height of the surface $f(\vec a)$ is illustrated by the blue bar in the lower right}{figure.6}{}}
\@writefile{brf}{\backcite{mathInsight:DirectionalDerivative}{{25}{6}{figure.6}}}
\citation{mathInsight:DirectionalDerivativeExamples}
\@writefile{brf}{\backcite{mathInsight:DirectionalDerivativeExamples}{{26}{25}{equation.25.12}}}
\@writefile{toc}{\contentsline {section}{\numberline {26}Gradient as a derivative}{27}{section.26}}
\newlabel{term:Gradient_as_a_derivative}{{26}{27}{Gradient as a derivative}{section.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {27}Jacobian as a derivative}{28}{section.27}}
\newlabel{term:Jacobian_as_a_derivative}{{27}{28}{Jacobian as a derivative}{section.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {28}Hessian as a derivative}{28}{section.28}}
\newlabel{term:Hessian}{{28}{28}{Hessian as a derivative}{section.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {29}Hadamard Product}{29}{section.29}}
\newlabel{term:hadamard_product}{{29}{29}{Hadamard Product}{section.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {30}Kronecker Product}{29}{section.30}}
\newlabel{term:kronecker_product}{{30}{29}{Kronecker Product}{section.30}{}}
\bibstyle{IEEEtran}
\bibdata{Report}
\bibcite{chiang2005fundamental}{1}
\bibcite{akivis2012introduction}{2}
\bibcite{wiki:TriangularMatrix}{3}
\bibcite{wiki:GaussianElimination}{4}
\bibcite{wiki:InvertibleMatrix}{5}
\bibcite{press1987numerical}{6}
\bibcite{ding2006r}{7}
\bibcite{introduction_to_derivatives}{8}
\bibcite{intuition_for_the_derivative}{9}
\bibcite{opencalc2}{10}
\bibcite{wiki:PartialDerivative}{11}
\bibcite{khan:PartialDerivative}{12}
\bibcite{mathInsight:DirectionalDerivative}{13}
\bibcite{mathInsight:DirectionalDerivativeExamples}{14}
\@writefile{toc}{\contentsline {section}{\numberline {31}Trace of a Matrix}{30}{section.31}}
\newlabel{term:trace_of_a_matrix}{{31}{30}{Trace of a Matrix}{section.31}{}}
\@writefile{toc}{\contentsline {section}{References}{30}{section*.1}}
